{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from DPR.utils.utils_SH import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompose\n",
    "using https://github.com/andrewhou1/GeomConsistentFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GeomConsistentFR.RelightNet import RelightNet\n",
    "import imageio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = RelightNet()\n",
    "model.load_state_dict(torch.load('GeomConsistentFR/model_lighting_transfer/model_epoch106.pth'))\n",
    "model = model.float()\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "epoch = 200\n",
    "intrinsic_matrix = np.zeros((1, 3, 3))\n",
    "intrinsic_matrix[:, 0, 0] = 700.0\n",
    "intrinsic_matrix[:, 1, 1] = 700.0\n",
    "intrinsic_matrix[:, 2, 2] = 1.0\n",
    "intrinsic_matrix[:, 0, 2] = model.img_width/2.0\n",
    "intrinsic_matrix[:, 1, 2] = model.img_height/2.0\n",
    "intrinsic_matrix = torch.from_numpy(intrinsic_matrix)\n",
    "\n",
    "with torch.no_grad():\n",
    "    curr_mask_fill_nose = np.zeros((256, 256, 1))\n",
    "    curr_mask_fill_nose.fill(1)\n",
    "    curr_mask_fill_nose = torch.from_numpy(curr_mask_fill_nose)\n",
    "\n",
    "    curr_mask_fill_nose_3_channels = np.zeros((model.img_height, model.img_width, 3))\n",
    "    curr_mask_fill_nose_3_channels[:, :, 0] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "    curr_mask_fill_nose_3_channels[:, :, 1] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "    curr_mask_fill_nose_3_channels[:, :, 2] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "\n",
    "    def decompose(image_path):\n",
    "        curr_input_image = torch.reshape(torch.from_numpy(imageio.imread(image_path)/255.0), (1, 256, 256, 3)) \n",
    "        curr_reference_image = curr_input_image\n",
    "        curr_training_lighting = torch.from_numpy(np.zeros((model.batch_size, 4)))\n",
    "        \n",
    "        albedo, depth, shadow_mask_weights, ambient_light, full_shading, rendered_images, unit_light_direction, ambient_values, final_shading, surface_normals, estimated_unit_light_direction, estimated_ambient_light \\\n",
    "            = model(curr_reference_image.float().cuda(), epoch, intrinsic_matrix.cuda(), curr_mask_fill_nose.cuda(), torch.reshape(curr_training_lighting[:, 1:4].float().cuda(), (model.batch_size, 3, 1, 1)), torch.reshape(curr_training_lighting[:, 0].float().cuda(), (model.batch_size, 1, 1)))\n",
    "            \n",
    "        albedo, depth, shadow_mask_weights, ambient_light, full_shading, rendered_images, unit_light_direction, ambient_values, final_shading, surface_normals, estimated_unit_light_direction, estimated_ambient_light \\\n",
    "            = model(curr_input_image.float().cuda(), epoch, intrinsic_matrix.cuda(), curr_mask_fill_nose.cuda(), torch.reshape(estimated_unit_light_direction.float().cuda(), (model.batch_size, 3, 1, 1)), torch.reshape(estimated_ambient_light.float().cuda(), (model.batch_size, 1, 1)))\n",
    "            \n",
    "        rendered_images = rendered_images.permute(0, 2, 3, 1)\n",
    "        rendered_images = rendered_images.cpu().detach().numpy()\n",
    "        albedo = albedo.permute(0, 2, 3, 1)\n",
    "        albedo = albedo.cpu().detach().numpy()\n",
    "        depth = depth.permute(0, 2, 3, 1)\n",
    "        depth = depth.cpu().detach().numpy()\n",
    "        depth = -depth\n",
    "        depth = (depth-np.amin(depth))/(np.amax(depth)-np.amin(depth))\n",
    "            \n",
    "        final_shading = final_shading.cpu().detach().numpy()\n",
    "            \n",
    "        surface_normals = surface_normals.permute(0, 2, 3, 1)\n",
    "        surface_normals = surface_normals.cpu().detach().numpy()\n",
    "        surface_normals = 255.0*(surface_normals+1.0)/2.0\n",
    "\n",
    "        input_image = curr_input_image[0].detach().cpu().numpy()*255.0\n",
    "        input_image = input_image[:, :, ::-1]\n",
    "        rendered_image = 255.0*rendered_images[0, :, :, ::-1]*curr_mask_fill_nose_3_channels\n",
    "                \n",
    "        input_image[curr_mask_fill_nose_3_channels > 0] = rendered_image[curr_mask_fill_nose_3_channels > 0]\n",
    "\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_rendered_image.png', input_image)\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_shadow_mask.png', 255.0*shadow_mask_weights[0, :, :].cpu().detach().numpy()*np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width)))\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_albedo.png', 255.0*albedo[0, :, :, ::-1]*curr_mask_fill_nose_3_channels)\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_depth.png', 255.0*depth[0, :, :, :]*curr_mask_fill_nose.numpy())\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_shading.png', 255.0*final_shading[0, :, :]*np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width)))\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_surface_normals.png', surface_normals[0, :, :, ::-1]*curr_mask_fill_nose_3_channels)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # make directory for decomposed images\n",
    "    os.makedirs(\"./train_data_face_decomposed\", exist_ok=True)\n",
    "\n",
    "    # for every subdirectory under \"train_data_face\" directory\n",
    "    # for every image in the subdirectory\n",
    "    for dirs in tqdm(os.listdir(\"./train_data_face\")):\n",
    "        os.makedirs(f\"./train_data_face_decomposed/{dirs}\", exist_ok=True)\n",
    "        for file in os.listdir(f\"./train_data_face/{dirs}\"):\n",
    "            image_path = os.path.join(f\"./train_data_face_decomposed/{dirs}/\", file)\n",
    "            # resize to 256x256\n",
    "            img = Image.open(os.path.join(f\"./train_data_face/{dirs}/\", file))\n",
    "            img = img.resize((256, 256), Image.ANTIALIAS)\n",
    "            # save with postfix '_256x256.jpg'\n",
    "            img.save(image_path.split('.jpg')[0] + '_256x256.jpg')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                decompose(image_path.split('.jpg')[0] + '_256x256.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeomShadows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
