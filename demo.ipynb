{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from DPR.utils.utils_SH import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompose\n",
    "using https://github.com/andrewhou1/GeomConsistentFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c5952367d249a6a485ebf84a340f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0_EI_X5JVk.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-9e5f5eb76999>:31: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  curr_input_image = torch.reshape(torch.from_numpy(imageio.imread(image_path)/255.0), (1, 256, 256, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eI_7SimPnnQ.001\n",
      "HegkSmkiBos.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9e5f5eb76999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mdecompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_256x256.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-9e5f5eb76999>\u001b[0m in \u001b[0;36mdecompose\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0malbedo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadow_mask_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambient_light\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_shading\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrendered_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_light_direction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambient_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_shading\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurface_normals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_unit_light_direction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_ambient_light\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_input_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintrinsic_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_mask_fill_nose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimated_unit_light_direction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimated_ambient_light\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mrendered_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendered_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face-decomposition/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/face-decomposition/GeomConsistentFR/RelightNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, epoch, intrinsic_matrix, mask, target_lighting, target_ambient_values)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_to_line_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mminimum_distance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlight_x\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlight_x\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlight_y\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlight_y\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from GeomConsistentFR.RelightNet import RelightNet\n",
    "import imageio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = RelightNet()\n",
    "model.load_state_dict(torch.load('GeomConsistentFR/model_lighting_transfer/model_epoch106.pth'))\n",
    "model = model.float()\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "epoch = 200\n",
    "intrinsic_matrix = np.zeros((1, 3, 3))\n",
    "intrinsic_matrix[:, 0, 0] = 700.0\n",
    "intrinsic_matrix[:, 1, 1] = 700.0\n",
    "intrinsic_matrix[:, 2, 2] = 1.0\n",
    "intrinsic_matrix[:, 0, 2] = model.img_width/2.0\n",
    "intrinsic_matrix[:, 1, 2] = model.img_height/2.0\n",
    "intrinsic_matrix = torch.from_numpy(intrinsic_matrix)\n",
    "\n",
    "with torch.no_grad():\n",
    "    curr_mask_fill_nose = np.zeros((256, 256, 1))\n",
    "    curr_mask_fill_nose.fill(1)\n",
    "    curr_mask_fill_nose = torch.from_numpy(curr_mask_fill_nose)\n",
    "\n",
    "    curr_mask_fill_nose_3_channels = np.zeros((model.img_height, model.img_width, 3))\n",
    "    curr_mask_fill_nose_3_channels[:, :, 0] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "    curr_mask_fill_nose_3_channels[:, :, 1] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "    curr_mask_fill_nose_3_channels[:, :, 2] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "\n",
    "    def decompose(image_path):\n",
    "        curr_input_image = torch.reshape(torch.from_numpy(imageio.imread(image_path)/255.0), (1, 256, 256, 3)) \n",
    "        curr_reference_image = curr_input_image\n",
    "        curr_training_lighting = torch.from_numpy(np.zeros((model.batch_size, 4)))\n",
    "        \n",
    "        albedo, depth, shadow_mask_weights, ambient_light, full_shading, rendered_images, unit_light_direction, ambient_values, final_shading, surface_normals, estimated_unit_light_direction, estimated_ambient_light \\\n",
    "            = model(curr_reference_image.float().cuda(), epoch, intrinsic_matrix.cuda(), curr_mask_fill_nose.cuda(), torch.reshape(curr_training_lighting[:, 1:4].float().cuda(), (model.batch_size, 3, 1, 1)), torch.reshape(curr_training_lighting[:, 0].float().cuda(), (model.batch_size, 1, 1)))\n",
    "            \n",
    "        albedo, depth, shadow_mask_weights, ambient_light, full_shading, rendered_images, unit_light_direction, ambient_values, final_shading, surface_normals, estimated_unit_light_direction, estimated_ambient_light \\\n",
    "            = model(curr_input_image.float().cuda(), epoch, intrinsic_matrix.cuda(), curr_mask_fill_nose.cuda(), torch.reshape(estimated_unit_light_direction.float().cuda(), (model.batch_size, 3, 1, 1)), torch.reshape(estimated_ambient_light.float().cuda(), (model.batch_size, 1, 1)))\n",
    "            \n",
    "        rendered_images = rendered_images.permute(0, 2, 3, 1)\n",
    "        rendered_images = rendered_images.cpu().detach().numpy()\n",
    "        albedo = albedo.permute(0, 2, 3, 1)\n",
    "        albedo = albedo.cpu().detach().numpy()\n",
    "        depth = depth.permute(0, 2, 3, 1)\n",
    "        depth = depth.cpu().detach().numpy()\n",
    "        depth = -depth\n",
    "        depth = (depth-np.amin(depth))/(np.amax(depth)-np.amin(depth))\n",
    "            \n",
    "        final_shading = final_shading.cpu().detach().numpy()\n",
    "            \n",
    "        surface_normals = surface_normals.permute(0, 2, 3, 1)\n",
    "        surface_normals = surface_normals.cpu().detach().numpy()\n",
    "        surface_normals = 255.0*(surface_normals+1.0)/2.0\n",
    "\n",
    "        input_image = curr_input_image[0].detach().cpu().numpy()*255.0\n",
    "        input_image = input_image[:, :, ::-1]\n",
    "        rendered_image = 255.0*rendered_images[0, :, :, ::-1]*curr_mask_fill_nose_3_channels\n",
    "                \n",
    "        input_image[curr_mask_fill_nose_3_channels > 0] = rendered_image[curr_mask_fill_nose_3_channels > 0]\n",
    "\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_rendered_image.png', input_image)\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_shadow_mask.png', 255.0*shadow_mask_weights[0, :, :].cpu().detach().numpy()*np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width)))\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_albedo.png', 255.0*albedo[0, :, :, ::-1]*curr_mask_fill_nose_3_channels)\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_depth.png', 255.0*depth[0, :, :, :]*curr_mask_fill_nose.numpy())\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_shading.png', 255.0*final_shading[0, :, :]*np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width)))\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_surface_normals.png', surface_normals[0, :, :, ::-1]*curr_mask_fill_nose_3_channels)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # make directory for decomposed images\n",
    "    os.makedirs(\"./train_data_face_decomposed\", exist_ok=True)\n",
    "\n",
    "    # for every subdirectory under \"train_data_face\" directory\n",
    "    # for every image in the subdirectory\n",
    "    for dirs in tqdm(os.listdir(\"./train_data_face\")):\n",
    "        os.makedirs(f\"./train_data_face_decomposed/{dirs}\", exist_ok=True)\n",
    "        for file in os.listdir(f\"./train_data_face/{dirs}\"):\n",
    "            image_path = os.path.join(f\"./train_data_face_decomposed/{dirs}/\", file)\n",
    "            # resize to 256x256\n",
    "            img = Image.open(os.path.join(f\"./train_data_face/{dirs}/\", file))\n",
    "            img = img.resize((256, 256), Image.ANTIALIAS)\n",
    "            # save with postfix '_256x256.jpg'\n",
    "            img.save(image_path.split('.jpg')[0] + '_256x256.jpg')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                decompose(image_path.split('.jpg')[0] + '_256x256.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeomShadows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
