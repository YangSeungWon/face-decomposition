{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from DPR.utils.utils_SH import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompose\n",
    "using https://github.com/andrewhou1/GeomConsistentFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-0356148d3ddb>:25: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  curr_input_image = torch.reshape(torch.from_numpy(imageio.imread(image_path)/255.0), (1, 256, 256, 3))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 256, 256, 3]' is invalid for input of size 37632",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0356148d3ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mdecompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-0356148d3ddb>\u001b[0m in \u001b[0;36mdecompose\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcurr_input_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mcurr_reference_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_input_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcurr_training_lighting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 256, 256, 3]' is invalid for input of size 37632"
     ]
    }
   ],
   "source": [
    "from GeomConsistentFR.RelightNet import RelightNet\n",
    "import imageio\n",
    "\n",
    "model = RelightNet()\n",
    "model.load_state_dict(torch.load('GeomConsistentFR/model_lighting_transfer/model_epoch106.pth'))\n",
    "model = model.float()\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "epoch = 200\n",
    "intrinsic_matrix = np.zeros((1, 3, 3))\n",
    "intrinsic_matrix[:, 0, 0] = 700.0\n",
    "intrinsic_matrix[:, 1, 1] = 700.0\n",
    "intrinsic_matrix[:, 2, 2] = 1.0\n",
    "intrinsic_matrix[:, 0, 2] = model.img_width/2.0\n",
    "intrinsic_matrix[:, 1, 2] = model.img_height/2.0\n",
    "intrinsic_matrix = torch.from_numpy(intrinsic_matrix)\n",
    "\n",
    "with torch.no_grad():\n",
    "    curr_mask_fill_nose = np.zeros((256, 256, 1))\n",
    "    curr_mask_fill_nose.fill(1)\n",
    "    curr_mask_fill_nose = torch.from_numpy(curr_mask_fill_nose)\n",
    "\n",
    "    def decompose(image_path):\n",
    "        curr_input_image = torch.reshape(torch.from_numpy(imageio.imread(image_path)/255.0), (1, 256, 256, 3)) \n",
    "        curr_reference_image = curr_input_image\n",
    "        curr_training_lighting = torch.from_numpy(np.zeros((model.batch_size, 4)))\n",
    "        \n",
    "        albedo, depth, shadow_mask_weights, ambient_light, full_shading, rendered_images, unit_light_direction, ambient_values, final_shading, surface_normals, estimated_unit_light_direction, estimated_ambient_light \\\n",
    "            = model(curr_reference_image.float().cuda(), epoch, intrinsic_matrix.cuda(), curr_mask_fill_nose.cuda(), torch.reshape(curr_training_lighting[:, 1:4].float().cuda(), (model.batch_size, 3, 1, 1)), torch.reshape(curr_training_lighting[:, 0].float().cuda(), (model.batch_size, 1, 1)))\n",
    "            \n",
    "        albedo, depth, shadow_mask_weights, ambient_light, full_shading, rendered_images, unit_light_direction, ambient_values, final_shading, surface_normals, estimated_unit_light_direction, estimated_ambient_light \\\n",
    "            = model(curr_input_image.float().cuda(), epoch, intrinsic_matrix.cuda(), curr_mask_fill_nose.cuda(), torch.reshape(estimated_unit_light_direction.float().cuda(), (model.batch_size, 3, 1, 1)), torch.reshape(estimated_ambient_light.float().cuda(), (model.batch_size, 1, 1)))\n",
    "            \n",
    "        rendered_images = rendered_images.permute(0, 2, 3, 1)\n",
    "        rendered_images = rendered_images.cpu().numpy()\n",
    "        albedo = albedo.permute(0, 2, 3, 1)\n",
    "        albedo = albedo.cpu().numpy()\n",
    "        depth = depth.permute(0, 2, 3, 1)\n",
    "        depth = depth.cpu().numpy()\n",
    "        depth = -depth\n",
    "        depth = (depth-np.amin(depth))/(np.amax(depth)-np.amin(depth))\n",
    "            \n",
    "        final_shading = final_shading.cpu().numpy()\n",
    "            \n",
    "        surface_normals = surface_normals.permute(0, 2, 3, 1)\n",
    "        surface_normals = surface_normals.cpu().numpy()\n",
    "        surface_normals = 255.0*(surface_normals+1.0)/2.0\n",
    "\n",
    "        curr_mask_fill_nose_3_channels = np.zeros((model.img_height, model.img_width, 3))\n",
    "        curr_mask_fill_nose_3_channels[:, :, 0] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "        curr_mask_fill_nose_3_channels[:, :, 1] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "        curr_mask_fill_nose_3_channels[:, :, 2] = np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width))\n",
    "\n",
    "        input_image = curr_input_image[0].detach().cpu().numpy()*255.0\n",
    "        input_image = input_image[:, :, ::-1]\n",
    "        rendered_image = 255.0*rendered_images[0, :, :, ::-1]*curr_mask_fill_nose_3_channels\n",
    "                \n",
    "        input_image[curr_mask_fill_nose_3_channels > 0] = rendered_image[curr_mask_fill_nose_3_channels > 0]\n",
    "\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_rendered_image.png', input_image)\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_shadow_mask.png', 255.0*shadow_mask_weights[0, :, :].cpu().numpy()*np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width)))\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_albedo.png', 255.0*albedo[0, :, :, ::-1]*curr_mask_fill_nose_3_channels)\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_depth.png', 255.0*depth[0, :, :, :]*curr_mask_fill_nose.numpy())\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_shading.png', 255.0*final_shading[0, :, :]*np.reshape(curr_mask_fill_nose.numpy(), (model.img_height, model.img_width)))\n",
    "        cv2.imwrite(image_path.split('.jpg')[0] + '_surface_normals.png', surface_normals[0, :, :, ::-1]*curr_mask_fill_nose_3_channels)\n",
    "\n",
    "    # for every subdirectory under \"train_data_face\" directory\n",
    "    # for every image in the subdirectory\n",
    "    for root, dirs, files in os.walk(\"./train_data_face\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                # check if already decomposed\n",
    "                if os.path.isfile(os.path.join(root, file).split('.jpg')[0] + '_surface_normals.png'):\n",
    "                    continue\n",
    "                image_path = os.path.join(root, file)\n",
    "                decompose(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeomShadows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
